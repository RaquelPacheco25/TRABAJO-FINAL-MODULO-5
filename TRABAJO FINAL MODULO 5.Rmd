---
title: "TRABAJO FINAL MODULO 5"
author: "Raquel Pacheco"
date: "2023-05-28"
output: 
  html_document:
    toc: true 
    toc_depth: 5
    toc_float: 
      collapsed: false
      smooth_scroll: true
---
## **CLÚSTER JERÁRQUICO**
Del archivo BOL_BP_MAY_2017  seleccione los siguientes indicadores, para los bancos, sin considerar las columnas de TOTALES.
Activos productivos/total activos
Morosidad cartera total
Gastos de Operación/Margen Financiero
Rentabilidad del ejercicio/ activo promedio
Fondos disponibles/total depositos corto plazo
 Construya un cluster jerarquico. Grafique y comente su composición, usando al menos 2 distancias y dos métodos de clasificación
Construya un cluster no jerarquico. Determine el número óptimo de clusters, grafique y comente.

### Carga de las librerias
```{r librerias, message=FALSE, warning=FALSE, comment="", echo=TRUE}
library(openxlsx)
library(cluster)
library(usethis)
library(devtools)
library(ggplot2)
library(factoextra)
library(fpc)
library(dplyr)
library(NbClust)

```

### Carga y manipulacion de la base de datos 

```{r basededatos, message=TRUE, warning=FALSE, comment="", echo=TRUE}

data<-read.xlsx("C:\\Users\\CompuStore\\Desktop\\CURSOS\\CIENCIA DE DATOS\\MODULO 5\\parte 2\\BOL_BP_MAY_ 2017.xlsx",
                sheet = "INDICADORES")

# Eliminamos filas
data<-slice(data, -c(1:3, 5))

#Eliminamos las columnas de bancos de totales
data<-data[,-1]
data<-data[,-6]
data<-data[,-15]
data<-data[,-c(25:30)]


#Seleccionamos las variables a utilizar 

data<-data %>%
  filter(data$INDICADORES.FINANCIEROS=="NOMBRE DEL INDICADOR"|
    data$INDICADORES.FINANCIEROS=="ACTIVOS PRODUCTIVOS / TOTAL ACTIVOS"|
           data$INDICADORES.FINANCIEROS=="MOROSIDAD DE LA CARTERA TOTAL"|
           data$INDICADORES.FINANCIEROS=="GASTOS DE OPERACION  / MARGEN FINANCIERO"|
           data$INDICADORES.FINANCIEROS=="RESULTADOS DEL EJERCICIO / ACTIVO PROMEDIO"|
           data$INDICADORES.FINANCIEROS=="FONDOS DISPONIBLES / TOTAL DEPOSITOS A CORTO PLAZO")

# Trasponemos nuestra base
data<- data.frame(t(data))

# Convertimos la fila en el nombre de la columna
colnames(data) <- data[1, ]
data <- data[-1, ]

#Guardamos en una variable el nombre de los bancos
nombres<-data$`NOMBRE DEL INDICADOR`


#Ponemos en formato numerico
base<-as.data.frame(lapply(data[,-1], as.numeric))

# Estandarizamos 
base<-data.frame(scale(base))

#Convertimos como indice a los nombres
row.names(base)<-nombres

```

### Clúster Jerárquico - Distancia Euclidean y Método WAR.D

```{r jerEucli, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
cluster<-hclust(dist(base, method = "euclidean"),
                method = "ward.D")

plot(cluster, hang = 0.01, cex=0.8)

```
El dendograma sirve para clasifcar a un grupo dentro de un cluster, en este podemos observar que una primera instancia podrian haber 4 grupos formados, de los cuales en un primer nivel tenemos a los bancos  BP GUAYAQUIL, BP PACIFICO, BP PICHINCHA, BP BOLIVARIANO, BP LOJA,  BP MACHALA, BP AUSTRO, BP PRODUBANCO,  BP INTERNACIONAL, BP CITIBANK,  BP COOPNACIONAL,  BP GENERAL RUMIÑAHUI y  BP SOLIDARIO, los cuales están agrupados es decir comparten similitudes o características comunes según la medida de similitud; la distancia euclideana en este caso utilizada. Por otra parte, tenemos a los bancos BP DELBANK, BP D-MIRO S.A.  BP AMAZONAS,BP PROCREDIT, BP FINCA, BP BANCODEDESARROLLO, BP COMERCIAL DE MANABI, BP LITORAL, que podrían ser otro grupo, sin embargo, vemos que después estos 2 grupos se unen y forman uno solo, por lo que podriamos decir que practicamente sus distancias no son tan lejanas y a la final podriamos tener un dendograma con 3 grupos. Esto lo iremos viendo a medida que hacemos otros calculos. No obstante, podemos visualizar que el banco BP VISONFUND ECUADOR, pertenece a un solo grupo y de la misma manera el banco BP CAPITAL pertenece a otro grupo. Todos estos grupos estaban basados en la distancia euclideana y el metodo ward. 
 
### Clúster Jerárquico - Distancia Manhattan y Método Average

```{r jerMann, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
# Cambiamos el método 

cluster2<-hclust(dist(base, method = "manhattan"),
                 method = "average")

plot(cluster2, hang = 0.01, cex=0.8)
```
A diferencia del dendograma anterior utilizado otra distancia y otro método, en este caso, vemos que los grupos se han unido similarmente, por ejemplo tenemos que BP CAPITAL Y BP VISONFUND ECUADOR siguen siendo grupos separados, no obstante, visualizamos que la distancia manhattan y el metodo de averange en BP LITORAL a diferencia del anterior, forma un grupo aparte.

### Ambos dendogramas

```{r dendo2, message=TRUE, warning=FALSE, comment="", echo=TRUE}
# En una sola ventana los 2 graficos 

par(mfrow=c(1,2))

cluster<-hclust(dist(base, method = "euclidean"),
                method = "ward.D")

plot(cluster, hang = 0.01, cex=0.8)

cluster2<-hclust(dist(base, method = "manhattan"),
                 method = "average")

plot(cluster2, hang = 0.01, cex=0.8)

```


### ¿A qué distancia se encuentran los elementos? 

```{r dist, message=TRUE, warning=FALSE, comment="", echo=TRUE}

## Distancia euclideana 
distancia<- dist(base, method = "euclidean")
distancia

# ¿A qué grupo pertenecen los clúster?

cluster$merge

## ¿A qué distancia se encuentran los elementos?
## Distancia manhattan 
distancia2<- dist(base, method = "manhattan")
distancia2

# ¿A qué grupo pertenecen los clúster?

cluster2$merge


```

### Cortes

```{r cortes, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
# Realizando cortes

cutree(cluster, k=3)

plot(cluster, hang = 0.01, cex=0.8)
rect.hclust(cluster, k=3, border = "red")

# ¿A que grupo pertenecen?

grupos<-as.data.frame(cutree(cluster, k=3))
grupos

```

### Coeficiente de disividalidad

```{r coefi, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
## cluster 

ncluster<-diana(base, metric="euclidean")

par(mfrow=c(1,2))

```

El coeficiente de disividalidad nos dice que mientras mas cercano a 1, los modelos estan bien en hechos, en este caso nosotros obtenemos 0,82 por lo que podriamos decir que los cluster estan bien elaborados y agrupados de manera correcta. 

### Dendograma Final

```{r dendograma, message=TRUE, warning=FALSE, comment="", echo=TRUE}

cluster1<- hcut(base, k=3, stand=TRUE,
                hc_metric = "euclidean", 
                hc_method = "ward.D")
fviz_dend(cluster1, rect=1, cex= 0.5,
          k_colors = c("blue", "red", "orange")
)

```

## **CLÚSTER NO JERÁRQUICO - CLÚSTER K-MEDIAS **

### Cluster
```{r cluster, message=TRUE, warning=FALSE, comment="", echo=TRUE}

## cluster
cnj<-kmeans(base,3)
cnj

#Media de cada cluster 

cnj$centers

# Usando agregate 

aggregate(base, by= list(cnj$cluster), FUN = mean)

```

## Como se ven los grupos 

```{r kmedias, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
fviz_cluster(cnj, data=base)

require(cluster)
clusplot(base, cnj$cluster,
         color=T, shade = T,
         labels = 2, lines = 2)

```

Como podemos observar nosotros hemos puestos 3 grupos dado que en el dendograma dividmos los grupos en 3. Similar a los graficos anteriores, la agrupacion de los bancos es la misma, vemos que BP capital está lejos de los demas bancos, sin embargo en el segundo grupo vemos que el Banco Visionfund Ecuador se agrupa con Banco Solidario, Banco Rumiñahui, Citibank y Coopnacional, sin embargo los demas grupos pertenecen a un mismo grupo. Los dos componentes recogen el 83, 96% de variabilidad, por lo que podemos decir que un valor de viabilidad del 83,96% implica que esos dos componentes capturan y explican el 83,96% de la variabilidad total presente en los datos. 

### ¿Cuantos cluster son los optimos?

```{r funcion, message=TRUE, warning=FALSE, comment="", echo=FALSE}
  
# fix the functions
fviz_nbclust <- function (x, FUNcluster = NULL, method = c("silhouette", "wss", 
                                                           "gap_stat"), diss = NULL, k.max = 10, nboot = 100, verbose = interactive(), 
                          barfill = "steelblue", barcolor = "steelblue", linecolor = "steelblue", 
                          print.summary = TRUE, ...) 
{
  set.seed(123)
  if (k.max < 2) 
    stop("k.max must bet > = 2")
  method = match.arg(method)
  if (!inherits(x, c("data.frame", "matrix")) & !("Best.nc" %in% 
                                                  names(x))) 
    stop("x should be an object of class matrix/data.frame or ", 
         "an object created by the function NbClust() [NbClust package].")
  if (inherits(x, "list") & "Best.nc" %in% names(x)) {
    best_nc <- x$Best.nc
    if (any(class(best_nc) == "numeric") ) 
      print(best_nc)
    else if (any(class(best_nc) == "matrix") )
      .viz_NbClust(x, print.summary, barfill, barcolor)
  }
  else if (is.null(FUNcluster)) 
    stop("The argument FUNcluster is required. ", "Possible values are kmeans, pam, hcut, clara, ...")
  else if (!is.function(FUNcluster)) {
    stop("The argument FUNcluster should be a function. ", 
         "Check if you're not overriding the specified function name somewhere.")
  }
  else if (method %in% c("silhouette", "wss")) {
    if (is.data.frame(x)) 
      x <- as.matrix(x)
    if (is.null(diss)) 
      diss <- stats::dist(x)
    v <- rep(0, k.max)
    if (method == "silhouette") {
      for (i in 2:k.max) {
        clust <- FUNcluster(x, i, ...)
        v[i] <- .get_ave_sil_width(diss, clust$cluster)
      }
    }
    else if (method == "wss") {
      for (i in 1:k.max) {
        clust <- FUNcluster(x, i, ...)
        v[i] <- .get_withinSS(diss, clust$cluster)
      }
    }
    df <- data.frame(clusters = as.factor(1:k.max), y = v, 
                     stringsAsFactors = TRUE)
    ylab <- "Total Within Sum of Square"
    if (method == "silhouette") 
      ylab <- "Average silhouette width"
    p <- ggpubr::ggline(df, x = "clusters", y = "y", group = 1, 
                        color = linecolor, ylab = ylab, xlab = "Number of clusters k", 
                        main = "Optimal number of clusters")
    if (method == "silhouette") 
      p <- p + geom_vline(xintercept = which.max(v), linetype = 2, 
                          color = linecolor)
    return(p)
  }
  else if (method == "gap_stat") {
    extra_args <- list(...)
    gap_stat <- cluster::clusGap(x, FUNcluster, K.max = k.max, 
                                 B = nboot, verbose = verbose, ...)
    if (!is.null(extra_args$maxSE)) 
      maxSE <- extra_args$maxSE
    else maxSE <- list(method = "firstSEmax", SE.factor = 1)
    p <- fviz_gap_stat(gap_stat, linecolor = linecolor, 
                       maxSE = maxSE)
    return(p)
  }
}

.viz_NbClust <- function (x, print.summary = TRUE, barfill = "steelblue", 
                          barcolor = "steelblue") 
{
  best_nc <- x$Best.nc
  if (any(class(best_nc) == "numeric") )
    print(best_nc)
  else if (any(class(best_nc) == "matrix") ) {
    best_nc <- as.data.frame(t(best_nc), stringsAsFactors = TRUE)
    best_nc$Number_clusters <- as.factor(best_nc$Number_clusters)
    if (print.summary) {
      ss <- summary(best_nc$Number_clusters)
      cat("Among all indices: \n===================\n")
      for (i in 1:length(ss)) {
        cat("*", ss[i], "proposed ", names(ss)[i], 
            "as the best number of clusters\n")
      }
      cat("\nConclusion\n=========================\n")
      cat("* According to the majority rule, the best number of clusters is ", 
          names(which.max(ss)), ".\n\n")
    }
    df <- data.frame(Number_clusters = names(ss), freq = ss, 
                     stringsAsFactors = TRUE)
    p <- ggpubr::ggbarplot(df, x = "Number_clusters", 
                           y = "freq", fill = barfill, color = barcolor) + 
      labs(x = "Number of clusters k", y = "Frequency among all indices", 
           title = paste0("Optimal number of clusters - k = ", 
                          names(which.max(ss))))
    return(p)
  }
}



```

```{r optimos, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
#Numero de cluster optimos 

clustoptim<-NbClust(base, distance = "euclidea",
                    min.nc = 2, max.nc = 6,
                    method = "ward.D", index = "all")

fviz_nbclust(clustoptim)

cnj2<-kmeans(base,3)

```

Podemos ver que 13 metodos propusieron que sean 3 cluster, 6 metodos que sean 2 cluster, 2 metodos que 0 y 4 y 6 y solo un metodo que sean 5. Por esta razón vemos que si era optimo los 3 cluster que habiamos impuestos al principio. 

### Evaluamos el cluster

```{r evaluamos, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
cnj2<-kmeans(base,3)
silueta<- silhouette(cnj2$cluster, dist(base, method = "euclidean"))
fviz_silhouette(silueta)

```

Sin embargo al momento de evaluar al cluster observamos que existen dos observaciones negativas, lo que quiere decir que probablemente no se esten agrupando en el cluster correcto, por lo que debería replantearse el numero de clusters optimos. 

```{r evaluamos2, message=TRUE, warning=FALSE, comment="", echo=TRUE}
  
cnj2<-kmeans(base,2)
silueta<- silhouette(cnj2$cluster, dist(base, method = "euclidean"))
fviz_silhouette(silueta)

```

Finalmente decidimos agruparlos con 2 clusters y vemos que de esta forma no existen observaciones negativas e incluso podemos decir que dado la linea roja que es el promedio, las demas barras estan por encima de ella lo que indica que estan bien clasificados. 